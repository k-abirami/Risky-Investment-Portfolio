{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import concurrent.futures as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Member Names: Abirami, Brashan, Dylan, Jingling\n",
    "### Team Strategy Chosen: RISKY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Strategy for filtering the stocks within the csv file:\n",
    " * Given a dataframe of tickers, this function first creates a new empty dataframe including the name of the ticker, the price of it, beta, standard deviation, the market cap and its returns\n",
    " * In the filtering stages\n",
    "     - It first checks if there are any duplicates\n",
    "     - It then checks to confirm the the stock is traded on US markets\n",
    "     - Finally it confirms the daily volume from Jul 2 2021 to October 22 2021 is at least 10000\n",
    " * In order to get the beta calculations, we get the necessary data needed of the market (S&P500) which was obtained ouside of the function and stored in a dataframe\n",
    " * Then, with the help of threading, a for loop that goes through the entirety of the received dataframe and it ...\n",
    "  - Gets the yfinance data for each stock in the dataframe \n",
    "  - Calculates the price, beta, standard deviation and returns to a single row dataframe and adds said dataframe to the main dataframe that was created at the beginning of the function\n",
    " * It then returns the final dataframe after escaping the threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in a dataframe of tickers and filters out ones that are duplicates, not traded in the US \n",
    "#  or have an average volume less than 10000 for Jul 2 to Oct 22 2021. It produces a dataframe\n",
    "#  with all valid tickers and finance data to go with them.\n",
    "\n",
    "def filtering(Tickers):\n",
    "    \n",
    "    #Creates a new dataframe to store valid tickers and their financial data\n",
    "    Valid_Tickers =  pd.DataFrame({'Tickers': [],\n",
    "                                   'Price': [],\n",
    "                                  'Beta': [],\n",
    "                                  'STD': [],\n",
    "                                  'Returns': []})\n",
    "    \n",
    "    #makes sure there are no duplicates\n",
    "    for index in range(len(Tickers.index)):\n",
    "        if Tickers.iloc[index,0] in Tickers.iloc[index+1:]:\n",
    "            Tickers.drop([index])\n",
    "    \n",
    "    #Threading\n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        \n",
    "        #creates a thread for each Ticker to gets it's history data\n",
    "        datarow = [executor.submit(filtering_thread, Tickers.iloc[index,0]) for index in range(len(Tickers.index))]\n",
    "        \n",
    "        #Adds each ticker's data to the dataframe\n",
    "        for row in cf.as_completed(datarow):\n",
    "            Valid_Tickers = Valid_Tickers.append(row.result())\n",
    "\n",
    "    #Formats the data\n",
    "    Valid_Tickers.reset_index(inplace=True)\n",
    "    Valid_Tickers = Valid_Tickers[['Tickers', 'Price', 'Beta', 'STD', 'Returns']]\n",
    "    \n",
    "    #returns the dataframe with all the data\n",
    "    return (Valid_Tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in a Ticker, filters it to ensure it is traded in the US and as enough volume.\n",
    "#  It then grabs the finacial data and returns a dataframe with a single row \n",
    "#  containing the ticker and the financial data\n",
    "\n",
    "def filtering_thread(Ticker):\n",
    "    \n",
    "    #Gets data for filtering\n",
    "    stock = yf.Ticker(Ticker)\n",
    "    stock_hist = stock.history(start=data_start, end=data_end, interval='1d')\n",
    "    \n",
    "    #gets the data for 2021-07-02 to 2021-10-22 to check volume\n",
    "    volume_hist = stock_hist.iloc[2894:2973]\n",
    "    \n",
    "    #grabs stock info\n",
    "    info = stock.info\n",
    "\n",
    "    #Checks if stock is traded in the US\n",
    "    if 'market' in info and info['market'] == 'us_market' and not(volume_hist.empty):\n",
    "\n",
    "        #Checks if the daily volume is at least 10000\n",
    "        total_sum = stock_hist.Volume.sum(axis=0)\n",
    "        average = total_sum/(len (stock_hist))\n",
    "        if average >= 10000:\n",
    "\n",
    "            #Gets monthly histru for that time\n",
    "            monthly_hist=stock_hist.resample('MS').first()\n",
    "            prices = pd.DataFrame(monthly_hist['Close'])\n",
    "            monthly_returns = prices.pct_change()\n",
    "\n",
    "            #creates a dataframe for just the daily closing price \n",
    "            #  and another one for just daily returns\n",
    "            daily_price = pd.DataFrame(stock_hist['Close'])\n",
    "            daily_returns = daily_price.pct_change()\n",
    "\n",
    "            ####### Price #############\n",
    "\n",
    "            #Closing price for the last day availible (Nov 26 when run for competition)\n",
    "            price = stock_hist['Close'].iloc[-1]\n",
    "\n",
    "            ######## Beta #############\n",
    "\n",
    "            #Adds markets daily returns to the dataframe\n",
    "            daily_returns['Market'] = daily_market_returns['Close']\n",
    "\n",
    "            #Calculates beta\n",
    "            beta = daily_returns.cov() / daily_market_returns['Close'].var()\n",
    "\n",
    "            ######### STD #############\n",
    "\n",
    "            #calculated standard deviation\n",
    "            std = prices.pct_change().std()\n",
    "\n",
    "            #returns a dataframe with the tickers price, beta, std and a dataframe for it's returns\n",
    "            return pd.DataFrame({'Tickers': [Ticker],\n",
    "                               'Price': [price],\n",
    "                              'Beta': [beta.iat[1,0]],\n",
    "                              'STD': [std.Close],\n",
    "                              'Returns': [stock_hist['Close'].pct_change()]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Strategy for choosing the 1 sinlge riskiest stock\n",
    "\n",
    "* We gathered 3 stocks with the highest standard deviation on monthly returns to be the riskiest stocks. From these 3 stocks, we calculated the riskiest stock to be the one with the highest beta value.\n",
    "* Stocks with high standard deviation are considered risky as they are stocks with high volatility and great fluctuations with prices. In addition, stocks with high beta values are considered risky as they are more volatile when compared to the overall market. \n",
    "* Since standard deviation and beta are both measures of riskiness and we wanted to take both into consideration. We did so by narrowing down the stocks to those that are risky in terms of standard deviation and then the one that is riskiest in terms of beta\n",
    "* There are some limitations with this approach which we will touch on later that has to do with as unlucky set of data.\n",
    "\n",
    "\n",
    "* We calculated these riskier investments as the ones with higher standard deviations and beta values. Stocks with high standard deviation are considered risky as they are stocks with high volatility and great fluctuations with prices. In addition, stocks with high beta values are considered risky as they are more volatile when compared to the overall market. Furthermore, portfolios that are less diversified are more risky, and less diversified portfolios do have high standard deviation and beta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in a set of tickers and determines which ticker is the \n",
    "#  rickiest based on standard deviation and beta\n",
    "\n",
    "def riskiest (Tickers):\n",
    "    \n",
    "    # gets the 3 tickers with the highest standard deviation\n",
    "    largest3_std = Tickers.nlargest(3, ['STD'])\n",
    "    \n",
    "    # gets the highest beta value from the 3 tickers with the highest standard deviation\n",
    "    largest_beta = largest3_std.nlargest(1, ['Beta'])\n",
    "    \n",
    "    #returns the riskiest stock\n",
    "    return (largest_beta)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Discussion for our decision in choosing the stocks to include\n",
    "* After determining the riskest stock among all the qualified stocks in the given csv file, we now want to decide what other stocks we should include in our portfolio in order to achieve a high-risk level. We will use the characteristics of this riskest stock as our guide to choosing the remaining stocks. The key idea of our approach is to **minimize the effect of diversification**.\n",
    "* The following steps explain in detail our code and why we do this. \n",
    ">1. Firstly, we filter out 20 stocks that are most correlated to the riskest stock determined before. The purpose is to make sure the stocks in our final portfolio are highly correlated, and thus less diversified. As the riskest stock is expected to fluctuate a lot, we expect the rest of the stocks in the portfolio to change in a similar way, so that the total fluctuation is larger. \n",
    ">2. Now, we filter out the 9 riskest stocks from the list of 20 correlated stocks obtained in the previous step. To determine their risk level, we mainly look at their standard deviations, as this metric measures fluctuations. We only pick the 9 riskest stocks, because the minimum number of stocks we need to have is 10. To minimize the effect of diversification, we want minimum stocks in our portfolio. \n",
    "\n",
    "* Discussions:\n",
    "    * After designing step 1, we recognized that solely looking at the correlation will not guarantee a high-risk level. To illustrate, consider the case where stock A and stock B have a similar change pattern, say correlation is 0.9, yet, while stock A fluctuates dramatically, the extent to which stock B prices fluctuate can be minimal. Then, adding stock B to the stock A portfolio can decrease the risk level if the flucatuations in stock B can't make up for the risk lost due to diversification. Therefore, we will also consider the risk level of each individual stock, which is step 2. \n",
    "    * Finally, we will include a total of 10 stocks in our portfolio  (i.e., 1 riskest stock we determine before + 9 stocks picked in this process), with the property that, every stock is highly correlated to one single stock (the riskest one) and in a high-risk level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tickers is the dataframe with all the stock and their data (beta, std, mcap, returns)\n",
    "#Corr is the stock that is being used to get correlation (riskiest). It should be a dataframe\n",
    "#  similar to Tickers but with only one row.\n",
    "#  It produces a dataframe of 10 stocks and their data which will be the stock in Corr \n",
    "#  and 9 other most correlated and risky stocks.\n",
    "\n",
    "def other_9(Tickers, Corr):\n",
    "    \n",
    "    #creates a dataframe to store values\n",
    "    Correlation =  pd.DataFrame({'Tickers': [],\n",
    "                                 'Price': [],\n",
    "                                 'Beta': [],\n",
    "                                 'STD': [],\n",
    "                                 'Returns': [],\n",
    "                                 'Corr': []})\n",
    "    \n",
    "    #gets returns for the riskiest stock\n",
    "    returns = Corr.iloc[0,4]\n",
    "    \n",
    "    #loops through the tickers\n",
    "    for index in range(len(Tickers.index)):\n",
    "        \n",
    "        #makes sure it doesn't get correaltion with itself\n",
    "        if not(Tickers.iloc[index, 0] == Corr.iloc[0,0]):\n",
    "            \n",
    "            #gets the returns for new stock being checked for correlation\n",
    "            stock_returns = Tickers.iloc[index, 4]\n",
    "            \n",
    "            #combines the monthly returns for the risky and other stock in one dataframe\n",
    "            returns = pd.concat([returns, stock_returns], join='inner', axis=1)\n",
    "            returns.columns = ['Risky', 'Other']\n",
    "            \n",
    "            #adds correlation data to the main dataframe with all stocks and data\n",
    "            Correlation = Correlation.append(pd.DataFrame({'Tickers': [Tickers.iloc[index,0]],\n",
    "                                                            'Price': [Tickers.iloc[index,1]],\n",
    "                                                            'Beta': [Tickers.iloc[index,2]],\n",
    "                                                            'STD': [Tickers.iloc[index,3]],\n",
    "                                                            'Returns': [Tickers.iloc[index,4]],\n",
    "                                                            'Corr': [returns.corr().iat[0,1]]}))\n",
    "            \n",
    "            #removes the returns for the other stock\n",
    "            returns = returns[['Risky']]\n",
    "            \n",
    "    #Gets the top 20 most correlated stocks\n",
    "    most_correlated_20 = Correlation.nlargest(20, 'Corr')\n",
    "    \n",
    "    #Gets the top 9 riskiest stocks from the most correlated\n",
    "    risky_9 = most_correlated_20.nlargest(9, 'STD')\n",
    "    \n",
    "    #Combines the dataframe into one final stock with the risky stock\n",
    "    final = Corr.append(risky_9)\n",
    "    \n",
    "    #formatting\n",
    "    final.reset_index(inplace=True)\n",
    "    final = final[['Tickers', 'Price', 'Beta', 'STD', 'Returns', 'Corr']]\n",
    "    \n",
    "    #returns top 10 stocks\n",
    "    return(final)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Strategy for deciding the weights\n",
    "* Firstly, we assign 35% to the riskest stock. 35% is the maximum we can give to one single stock. We choose to do so because we aim to achieve a high risk. By distributing the most weight to the riskest stock, we want our final portfolio to behave more like the riskiest and thus fluctuate more. \n",
    "* Secondly, we assign 5% to all of the rest 9 stocks. 5% is the minimum we can give to every single stock. \n",
    "* Finally, we distribute the other 20% to only the second third and fourth stocks in our list in the way that the new weight distribution gives us the highest total standard deviation. To do this, we use 2 for loops to interate between between all the distributions, calculate the standard deviation of the entire portfolio and choose the combination that maximises standard deviation. We don't give more weightings to the last 6 stocks because they are less risky and doing so will create more diversification.\n",
    "* One limitation of this program is the fact that we can't iterate through all the ways to distribute the final $\\$20000 between all 9 other stocks. Doing so creates exponetial blow up and trying to do it for all 9 would take 66 years. The most we can iterate though ina resonable time is 3 which takes about 0.6 seconds. Once you start doing 4, it takes a couple minutes and anything more than that will take too long. For this reason, we are only iterating between distribution for 3 stocks. Those 3 stocks are the 3 with the highest standard deviation since they are the most likely to increase riskiness level by being given more weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in a list of 10 tickers and produces weightings for a portfolio to maximise risk level\n",
    "\n",
    "def weightings(Tickers): \n",
    "    \n",
    "    #Creates list of tickers in the order of risk level \n",
    "    Tickers10 = final10['Tickers'].iloc[0:10].tolist()\n",
    "\n",
    "    #Creates the initial weight distribution, which is not set in stone\n",
    "    weights = [0.35, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
    "\n",
    "    #Creates a list to store Tickers except the second to forth most risky stocks\n",
    "    RestTickers = Tickers10[4:10]\n",
    "    RestTickers.insert(0, Tickers10[0])\n",
    "\n",
    "    #Gets data from yf for those tickers, and stores closing pirces in a dataframe\n",
    "    data = yf.download(RestTickers,start= \"2010-01-01\", end= datetime.today(),period='1d')\n",
    "    restprices = pd.DataFrame(data['Close'])\n",
    "    restprices = restprices.dropna()\n",
    "    restprices.columns = RestTickers\n",
    "\n",
    "    #Creates a list for the weights for each of the stocks in RestTickers (these will not changed) \n",
    "    restweights = weights[4:10]\n",
    "    restweights.insert(0, weights[0])\n",
    "\n",
    "    #Creates a column in the prices dataframe for the unchanging tickers with for the portfolio value overtime\n",
    "    restprices['Portfolio_Value'] = 0\n",
    "    restprices['Portfolio_Value'].iloc[0]=100000*0.65 #sets first row to be the total value of these 7 stocks which is $65000\n",
    "\n",
    "    #Calculates the value of each of the 7 stocks based on each of their weights\n",
    "    for ticker in RestTickers:\n",
    "        restprices[ticker+'_SharesPurchased']= 0\n",
    "        restprices[ticker+'_SharesPurchased'].iloc[0] = 100000 * restweights[RestTickers.index(ticker)] / restprices[ticker][0]\n",
    "\n",
    "    #Calculates the total portfolio value over time\n",
    "    for x in range(1,len(restprices.index)):\n",
    "        for ticker in RestTickers:\n",
    "            restprices['Portfolio_Value'].iloc[x] += restprices[ticker+'_SharesPurchased'].iloc[0] * restprices[ticker].iloc[x]\n",
    "\n",
    "    #Creates a list of the Tickers of the second, third and forth most risky stocks\n",
    "    Two_Three_Four_Tickers = [Tickers10[1], Tickers10[2], Tickers10[3]]\n",
    "\n",
    "    #Gets closing prices from yahoo finance for each of these stocks\n",
    "    data1 = yf.download(Two_Three_Four_Tickers,start= \"2010-01-01\", end= datetime.today(),period='1d')\n",
    "    prices = pd.DataFrame(data1['Close'])\n",
    "    prices = prices.dropna()\n",
    "    prices.columns = Two_Three_Four_Tickers\n",
    "\n",
    "    #Sets the starting value of each stock to be $100000\n",
    "    #We will later find a portion of the values when determining the riskest weightings for these stocks\n",
    "    for ticker in Two_Three_Four_Tickers:\n",
    "        prices[ticker+'_SharesPurchased']= 0\n",
    "        prices[ticker+'_Value']=0\n",
    "        prices[ticker+'_Value'].iloc[0]=100000\n",
    "        prices[ticker+'_SharesPurchased'].iloc[0] =  100000 / prices[ticker][0]\n",
    "        \n",
    "    #Calculates value over time for each stock\n",
    "    for x in range(1,len(prices.index)):\n",
    "        for ticker in Two_Three_Four_Tickers:\n",
    "            prices[ticker+'_Value'].iloc[x] = prices[ticker+'_SharesPurchased'].iloc[0] * prices[ticker][x]\n",
    "\n",
    "    #Combines the two dataframes into one that will contain all value and pricing data overtime\n",
    "    combined = pd.concat([restprices,prices],join='inner', axis=1)\n",
    "\n",
    "    #Creates a new dataframe to store standard deviations and their weightings\n",
    "    totalstd = pd.DataFrame(index=range(0, 21))\n",
    "    totalstd['Standard_Deviation'] = ''\n",
    "    totalstd['Weight_2'] = ''\n",
    "\n",
    "    #Creates a dataframe to store the value of each of the stocks that have a dynamic weightings\n",
    "    value_2= combined[Tickers10[1]+\"_Value\"]\n",
    "    value_3= combined[Tickers10[2]+\"_Value\"]\n",
    "    value_4= combined[Tickers10[3]+\"_Value\"]\n",
    "\n",
    "    #Loops through all possible ways to ditribute $20000 in portions of $1000\n",
    "    for x in totalstd.index:\n",
    "        \n",
    "        #creates a dataframe to store the weightings of the first stock and the standard deviation that goes with it\n",
    "        weight23 = pd.DataFrame(index=range(0,21-x))\n",
    "        weight23['Standard_Deviation'] = ''\n",
    "        weight23['weight1'] = x\n",
    "\n",
    "        #loops through all ways to distribute the remaining cash not used by the first stock to the second and third stock\n",
    "        for y in range(0,21-x):\n",
    "            #Calculates the value and standard deviation of the portfolio for the current weightings\n",
    "            total_values= combined.Portfolio_Value + (value_2 *(5+x)/100) + (value_3 * (5+y)/100) + (value_4 * (25-x-y)/100)\n",
    "            portfolio = pd.DataFrame(total_values)\n",
    "            returns = pd.DataFrame(portfolio.pct_change())\n",
    "            \n",
    "            #Adds the standard deviation to a dataframe\n",
    "            weight23['Standard_Deviation'].iloc[y] = returns.std()[0]\n",
    "\n",
    "        #Calculates the biggest standard devaition of the dataframe\n",
    "        #  which changes how cash was distributed betweeen the second and third stock\n",
    "        std1 = weight23['Standard_Deviation'].max()\n",
    "        \n",
    "        #Adds the max standard deviation and it's weights to another dataframe which \n",
    "        #  holds standard deviations for different amounts cash in the first stock\n",
    "        weight2 = weight23.index[weight23['Standard_Deviation']==std1].tolist().pop(0)\n",
    "        totalstd['Weight_2'].iloc[x] = weight2\n",
    "        totalstd['Standard_Deviation'] = std1\n",
    "\n",
    "    ## Determines the weighting for the stock with the biggest standard deviation\n",
    "    diff = totalstd[totalstd.Standard_Deviation == totalstd['Standard_Deviation'].max()].index[0]\n",
    "    \n",
    "    #Updates the weights in the original weights dataframe\n",
    "    weights[1]=(5 + diff)/100\n",
    "    weights[2]=(5 + totalstd.iloc[diff].Weight_2)/100\n",
    "    weights[3]=(25 - diff - totalstd.iloc[diff].Weight_2)/100  \n",
    "    \n",
    "    #Creates a final dataframe to output\n",
    "    FinalPortfolio = Tickers\n",
    "    \n",
    "    #adds weights to the dataframe\n",
    "    weights = pd.Series(weights)\n",
    "    FinalPortfolio['weights'] = weights\n",
    "    \n",
    "    #Calculates number of shares of bought of each stock\n",
    "    FinalPortfolio['Shares'] = (FinalPortfolio.weights * 100000) / FinalPortfolio.Price\n",
    "    \n",
    "    #Creates column for the value of each stock within the portfolio\n",
    "    FinalPortfolio['Value'] = FinalPortfolio.Price * FinalPortfolio.Shares\n",
    "    \n",
    "    #Creates a new colummn for the weights at the end of the dataframe with the numbers in terms of %\n",
    "    FinalPortfolio['Weight'] = FinalPortfolio.weights * 100\n",
    "    \n",
    "    #Formatting\n",
    "    FinalPortfolio = FinalPortfolio[['Tickers', 'Price', 'Shares', 'Value', 'Weight']]\n",
    "    FinalPortfolio.columns = ['Ticker', 'Price', 'Shares', 'Value', 'Weight']\n",
    "    FinalPortfolio.index = FinalPortfolio.index+1\n",
    "    \n",
    "    #returns a final portfolio with the purchasing data for the stock being baught\n",
    "    return(FinalPortfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Next Steps:\n",
    "    \n",
    "Our project evaluated the risk of stocks based on high standard deviation, high beta value and low diversification. However there are other factors that could have helped to determine the risk level of stocks. These include calculating R-squared (coefficient of determination), Value at Risk (VaR) and/or market capitalization. \n",
    "\n",
    "The coefficient of determination displays the percentage of a fund or security's movements based on movements in a benchmark index (for example the Standard & Poor's 500 index). This value helps determine how likely a stock would drop if it's benchmark index dropped. A stock with a high R squared value measured against the riskiest stock from the portfolio can be considered risky. Value at Risk provides a worst-case scenario analysis where it calculates the percent of loss based on a time period and confidence level. It measures the risk of loss for investments. A stock with a high VaR value would be risky as the probability of losing that investment is high. Market cap is the total value of a company’s stocks. It is calculated by multiplying the number of outstanding shares with the current price of each share. A company with a small market cap is deemed more risky than a company with a large market cap. This is because companies with small market caps tend to be young companies with more uncertainties and high volatility. Incorporating these additional risk factors into our project could provide a better portfolio of risky stocks as there would be more factors evaluated with each stock. \n",
    "\n",
    "When it comes to limitations to our project, the steps that we take to come up with the riskiest stocks may not produce the best results. For example, when we consider 20 stocks that are highly correlated with the riskiest stock, we would not consider stocks that are risky (according to the beta value and standard deviation) but not correlated with the riskiest stock. One way we can fix the issue is by dynamically setting a minimum value for the correlation coefficient and then gather the stocks that fit the requirement. In the case that there are less than 9 stocks, we would decrease the minimum value of the correlation coefficient until we reach the required number of stocks.\n",
    "\n",
    "Another limitation comes from the narrowing down of stocks using different values. There can be unlucky set of data where you do not even come close to ending up with a risky set of stocks. Take for example a set where stock A has a STD (standard devaition) of 20 and a beta of 1, stock B has a STD of 8 and a beta of 1.01, and stock C has a STD of 7 and a beta of 1.1. If these were the 3 stocks with the highest STD when trying to find the riskiest, clearly the top riskiest is stock A. But since we choose our riskiest stock off of beta from the top 3 STDs, our algorithm would produce stock C as the riskiest. If we were to fix this issue, we could create a points system that assigns certain amounts of points for each measure of risk. In the above scenario, stock A would get alot of points for it's STD and the other stocks wouldn't be able to get enough from beta to catch up. Perfecting the points values could take awhile but it would eliminate the possibility of the above situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- AGN: No data found, symbol may be delisted\n",
      "- CELG: No data found, symbol may be delisted\n",
      "- PCLN: None\n",
      "- RTN: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  7 of 7 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faelk\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faelk\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total value is: $100000.0\n",
      "Total weight is: 100.0%\n"
     ]
    }
   ],
   "source": [
    "#Reads in the csv file \n",
    "Tickers = pd.read_csv('Tickers.csv', header = None)\n",
    "Tickers.columns = [['Tickers']]\n",
    "\n",
    "#Sets constants for the data being collected\n",
    "data_start = '2010-01-01'\n",
    "data_end = datetime.today()\n",
    "\n",
    "#Grabs market data for S&P500\n",
    "market_index = yf.Ticker('^GSPC')\n",
    "market_hist = market_index.history(start=data_start, end=data_end, interval='1d')\n",
    "market_hist = pd.DataFrame(market_hist['Close'])\n",
    "daily_market_returns = market_hist.pct_change()\n",
    "\n",
    "#Filters the stocks and gets their data\n",
    "Tickers = filtering(Tickers)\n",
    "\n",
    "#Determines the riskiest stock\n",
    "riskiest = riskiest(Tickers)\n",
    "\n",
    "#Chooses the other 9 stocks\n",
    "final10 = other_9(Tickers, riskiest)\n",
    "\n",
    "#Gets the weighting for the 10 stocks\n",
    "FinalPortfolio = weightings(final10)\n",
    "\n",
    "#Calculates the total weights and value to prove the porfolio is valid\n",
    "totalValue = FinalPortfolio.Value.sum(axis=0)\n",
    "totalWeight = FinalPortfolio.Weight.sum(axis=0)\n",
    "print('Total value is: $' + str(totalValue))\n",
    "print('Total weight is: ' + str(totalWeight) + '%')\n",
    "\n",
    "#Creates a dataframe for the .csv file and creates the csv\n",
    "Stocks = FinalPortfolio[['Ticker', 'Shares']]\n",
    "Stocks.to_csv('Stocks_Group_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Value</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OXY</td>\n",
       "      <td>32.009998</td>\n",
       "      <td>1093.408367</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLB</td>\n",
       "      <td>31.410000</td>\n",
       "      <td>159.184974</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIG</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>89.206067</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MS</td>\n",
       "      <td>101.120003</td>\n",
       "      <td>247.231006</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>76.335878</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAC</td>\n",
       "      <td>45.759998</td>\n",
       "      <td>109.265738</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COP</td>\n",
       "      <td>74.830002</td>\n",
       "      <td>66.818119</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BA</td>\n",
       "      <td>199.210007</td>\n",
       "      <td>25.099141</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COF</td>\n",
       "      <td>155.860001</td>\n",
       "      <td>32.080072</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SPG</td>\n",
       "      <td>169.029999</td>\n",
       "      <td>29.580548</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker       Price       Shares    Value  Weight\n",
       "1     OXY   32.009998  1093.408367  35000.0    35.0\n",
       "2     SLB   31.410000   159.184974   5000.0     5.0\n",
       "3     AIG   56.049999    89.206067   5000.0     5.0\n",
       "4      MS  101.120003   247.231006  25000.0    25.0\n",
       "5       C   65.500000    76.335878   5000.0     5.0\n",
       "6     BAC   45.759998   109.265738   5000.0     5.0\n",
       "7     COP   74.830002    66.818119   5000.0     5.0\n",
       "8      BA  199.210007    25.099141   5000.0     5.0\n",
       "9     COF  155.860001    32.080072   5000.0     5.0\n",
       "10    SPG  169.029999    29.580548   5000.0     5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displays the final portfolio\n",
    "FinalPortfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Insert Names Here. Abirami, Brashan, Dylan, Jingling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
